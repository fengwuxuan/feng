第一章、python对象
1. Python的核心：一切皆对象
2. python中内建对象均是静态初始化的，一般来说类型对象是不能静态初始化的，也不能在栈空间上生存。
3. 定长对象与变长对象
4. PyObject：ob_refcnt+ob_type  PyVarObject：ob_refcnt+ob_size+ob_type，实际的内建对象会有一块维护的数据
5. 类型对象：ob_type，保留的是类的元信息，包括类名、大小等等，也是利用这个域实现多态性
6. 对象创建：AOL与COL两种，AOL是泛型编程，主要根据ob_type进行创建，COL是根据具体的类型直接创建。
7. 函数：内建函数大多也是泛型，通过ob_type进行关联调用。
8. 引用计数：通过引用计数进行垃圾回收，为了效率和空间创建了对象池计数

第二章、整数对象
1. 整数的实现是通过PyIntObject对象实现的，这里引入了另外一种对象的分类方式：可变（mutable）VS 不可变（inmutable），这里PyIntObject对象就是不可变的。其不变性指的是它维护的真实数值是不可变的，即一旦该对象被创建，那么它就不能再被改变值了。在python中整数对象其实就是对C的long类型的包装，多了一些类型的元信息（类型、大小、函数指针（第一张讲到这些函数也是一个个的对象，有点模板类的意思，根据函数指针获取ob_type调用对应的实例对象（这里抛出自定义类的函数指针对象***********************）））
2. 对象池：Python核心设计策略之一，从上面可以看到整数对象甚至是其他对象都是不可变的，那么面对众多的访问，就会造成python的瓶颈，因此对象池机制应运而生，几乎所有的内建对象都有自己的对象池机制。它将某个类型的诸多对象组合在一起，在解释器运行时即存在，直至解释器退出才会被注销。
3. 操作引出：整数的加减等操作返回的是一个新的对象。
4. Python 宏和函数：在Python中对某些频繁执行的函数提供了函数和宏两个版本，宏版本可以省去一次函数调用的开销，但是牺牲了类型安全。而函数版会多方检查类型安全性。
5. 对象的创建：第一章中讲过Python对象的创建有两种：C API 与类型对象PyInit_Type，其中C API又分为两类：泛型API AOL（模板型） 与类型相关API COL（只能作用在某一种类上），而类型对象的出现更过的是为了解决自定义类的问题，对于一个类A，Python不可能实现提供PyA_New这样的API（Python里面的对象都是静态创建的），Python会根据A的类型对象创建类对象（这里也抛出一个问题：A的类型对象是如何确定的？）。
   回到整数对象的创建：主要利用的是COL类型的API创建，PyInt_FromLong，PyInt_FromString，PyInt_FromUnicode三个接口，后两者实际就是先将字符串等对象转换为浮点数，然后在开勇PyInt_FromFloat，这实际就是适配器模式的实现。
   小整数对象：Python中所有对象都存活在系统堆上，而且是静态创建的，那么其创建方式就是malloc，而对于小整数对象会造成效率下降，因此就是使用了对象池技术。而受益于Python整数对象的不变性，所有的整数对象都可以被任意的共享，python中小整数为[-5,257]，这些小整数一开始就被创建缓存在内存里，使用时取出即可。
   大整数对象：考虑到时间和空间的问题，Python运行环境将提供一块内存空间轮流供大整数对象使用，谁需要谁使用，这样就避免了不断的malloc又考虑了内存。其具体实现是利用了PyIntBlock结构（单向列表），用于管理一定的python 整数对象，而多个block的组织也是通过链表。此外python会构建一个free_list管理所有的空前内存。Blcok开始只是一个数组最后转换为一个链表，其连接是利用P有Object的ob_type类型，但是这样就放弃了类型安全的坚持，不过也可以连接整数类型的派生类了。
   注意小整数是共享的，但是大整数并不会。
   因此当新建整数对象时会先判断是否是小整数对象，然后选择合适的操作。
   当一个python整数对象被销毁时，它所占的内存不会被释放归还给系统，而是继续被python保存，变成自由内存，将来可供别的整数对象使用。但其实这样是python的一个漏洞，可以利用此漏洞吃完内存。 

第三章、字符串对象
1. 字符串对象也是一个不变对象，但是变长对象，因此它是不支持添加和删除操作的。此外它和C中相似，也是以\0结束，但是支持中间定义多个\0.字符串对象维护了一个ob_shash字段，初始为-1，用于保留hash值。此外ob_sstate表示该对象是否经过了intern机制处理，hash和intern使字符串在虚拟机上的执行效率提高了20%。
2. 空串：python保留了一个字符串对象nullstring用于处理空串，内部通过intern机制共享。
3. intern机制：python的intern机制保证在程序运行期间只有唯一的一个特定字符串存在，比如一个字符串为“ruby”，一旦经过intern，内部只会维持一个对象，当创建相同字符串对象时，实际是被引用了唯一的字符串。这样就可以节省内存。注意字符串的派生类是不会支持intern的。而intern的具体实现就是在系统中维护一个（key，value）的interned集合，记录着被intern处理的字符串对象，如果一个新的字符串可以在该集合中查找到，python会先为他创建一个对象，然后引用interned之后注销新创建的对象，实际就是一个temp对象。intern之后的对象有两种状态：第一种寿与天齐，第二种这是可以被注销的。
4. 字符缓冲池：给单字符创建了一个小的缓冲池，类似于小整数缓冲池。但不同的是小整数缓冲池是在python初始化创建的，而字符缓冲池则是以静态变量的形式存在的。字符缓冲池一开始是空的，如果有单字符创建，则会利用intern处理后放入缓冲池。
5. 效率问题：字符串的+操作是及其丑陋的操作，假设有多个字符串，它会两两合并，每次都要重新申请内存，因此建议使用join函数，它会先计算所有字符串的空间大小，然后统一申请合并。

第四章、list对象
1. python list对象类似于C++ 的vector对象，他是可变的，其定义如下：
   typedef struct {
     PyObject_VAR_HEAD; #存放元信息，ob_size表示存放了多少个元素
     PyObject **ob_item; # 指向元素列表的指针，可以看出他是PyObject类型的指针，也就是说可以存放任何python对象
     int allocated; #分配的元素个数， 可以看出其机制类似于Vector，不是用时才动态分配内存的。
   }PyListObject;
2. python创建list的途径只有一条----PyList_new。该函数接受size参数，允许创建时指定初始元素个数，创建时如果元素个数会溢出，那么停止创建，如果满足缓冲池的要求就使用缓冲池对象。如果不可用则在系统堆上申请内存，创建新的对象，此时还会为垃圾收集机制提供一些准备工作。注意list缓冲池最多维持80个对象。
3. list设置元素与插入元素的区别：及list[i] = var 与 list.insert(i,var)的区别，后者可能会使内存发生变化，因为List存放的元素不是一致的。插入操作实际是调用另外python内部的insl，它有一个条件就是对象必须有足够的内存来保证元素的插入，因此如果会超出内存就会调用resize函数。当newsize小于allocated且大于allocated的一半时简单调整ob_size的值，若小于一半则realloc收缩列表的内存空间。
4. 删除元素：一定会触发内存搬移操作，通过menmove来实现
5. 对象缓冲池：缓冲池对象实际来源于删除的list对象，一开始它是空的，等list对象销毁时会检查缓冲池是否已满及list对象是否在里面，若都没有则放入。

第五章、Dict对象
1. 不同于C++ map使用红黑树（查找o(lgn)）,python dict为了效率使用的是hash散列表，查找效率o(1),解决冲突的方法是开放定址法（二次探测函数）。
2. Dict对象中entry有三个状态：active、dummy（伪删除）、unused（key和value均为null），当记录被删除时不是直接被删除而是转为dummy，这样是为了防止探查链因此而中断。当python搜索到dummy时，会认为它虽然是无效的，但是其后面的元素还是有效的。
3. Dict中的key和value其实都是PyObject基类对象指向的。
4. 内部关联：Dict中维护ma_fill、ma_used、ma_mask、ma_table、ma_smalltable、ma_lookup，ma_fill是active+dummy记录个数，ma_used是active数量，ma_table指向一片entry的内存空间，如果记录数小于八，则使用ma_smalltable, ma_lookup是查找函数指针。
5. 对象创建：使用内部的PyDict_new接口创建，依旧使用了对象缓冲池。
6. 元素搜索：lookdict与lookdict_string两种，实际上算法是一致的，后者是前者的特殊情况。需要注意的是他们的返回结果永远是一个entry而不是null，如果搜索不到那么返回的entry 的value为null。搜索是会比较两种相同：值相同、引用相同（引用的内存地址相同），先比较后者再比较前者，只要相同就停止搜索。当搜索到dummy或unused时需要完整的设置hash、key、value
7. 缓冲池：与PyList的机制一样。


第六章、python的编译结果
1. python是解释性的语言：这句话是不对的，它和java等没有太大区别，总体也是分为虚拟机、字节码两个部分。虚拟机的执行原理都是一样的，但是python虚拟机的抽象层次更深，离真实机器更远。
   python执行过程：py文件---->虚拟机编译---->pyc文件---->虚拟机执行---->执行结果，windows下虚拟机为pythonXX.dll,linux下为bin文件
   java执行过程：.java文件---->javac编译---->.class字节码文件---->调用java命令执行---->执行结果。
2. pyc: PyCodeObject对象，编译完成后结果会保存在pyCodeObject对象中，执行结束后保存到pyc文件中，下次执行时如果没有改动源文件那么久从pyc文件直接重建pycodeobject对象。那么编译出来的东西有哪些呢？主要有字节码、（字符串、常量等对字节码有用的信息）
   在编译时，python将任何一个作用域或者命名空间当做一个code block，然后为其生成一个PyCodeObject对象。对于命名空间是可以嵌套的形成命名空间链。
   pycodeObject各个域的作用：
   co_argcount：作用域的个数，即code block位置参数的个数
   co_nlocal：局部变量个数
   co_stacksize：需要的栈空间大小
   co_code：字节码的指令序列
   co_consts：存储常量
   co_names：存放字符
   co_varnames：局部变量名集合
   co_freevar：闭包需要的东西
   co_cellvars：内部嵌套函数的变量集合
   co_filename：.py文件路径
   co_name：block名称
   co_firstlineno：起始行
3. 为什么有的python文件会生成pyc而有的不生成呢，这是因为import机制会触发pyc的生成，而没有被import的文件，python会认为他不会被重复使用，就不会被生成pyc。除此之外可以用py_compile、compiler等python标准库生成。
4. python中访问pycodeobject的属性可以用compile内建函数构建code对象进行访问。
5. python创建pyc文件时会先写入pyc_magic（整数），它用来保证python版本，保证版本兼容性（不同版本的pyc文件不能随意加载）。然后会写入时间信息，当py改变时会根据时间判断是否重新编译。然后写入pycodeobject文件完成创建。将所有的对象写入字节流，类型信息写入标识，
6. python提供对字节码进行解析的工具dis。

第七章、python虚拟机框架
1. 可执行文件的执行机制：当在函数g中执行函数f的调用时，系统会在g的栈帧之后创建f的栈帧，在发生函数调用时系统会保存上一个栈帧的栈指针esp和帧指针edp，当调用结束再恢复。
2. python虚拟机不是直接执行pycodeobject，而是执行它对应的pyframeobject，它对应一个命名空间，即对应了栈帧，是对栈帧的模拟。
3. python sys模块有个get_frame函数可以获得frame信息。
4. 命名空间：分为local、global、内建，与python base里面的内容相结合。
5. Windows下python运行时会有一个主进程，其拥有一个主线程及若干线程，python主要以线程为主,对于多线程来说，python中的modules是共享。同Windows下的多进程相似，理论上来说python是可以运行多个解释器的，但是通常只有一个解释器，它维护多个线程，线程同步则是利用GIL(global interpreter lock)：全局解释器锁，后面会重点介绍。

第八章、python虚拟机中的一般表达式和控制流
1. 一般表达式主要是对象创建语句、打印语句等，因此其使用的基本就是local命名空间以及pyframe的运行时栈。
2. 控制流主要是if、while、for等语句的实现，都是一堆指令集，需要时查看即可，注意python中是没有switch控制语句的哦。
3. 需要注意一下迭代器是的实现：Python在运行时会先获取栈顶的list等可迭代对象，然后通过PyObject_generater对象来实现list等对象的迭代。PyObject_generater主要使用对应迭代对象的类型对象中的tp_iter来获得与对象关联的迭代器。在Python中迭代器与C++、java等语言的设计是一样的，都是对底层接口的封装，这也符合GoF的迭代器设计模式思想。在C++中vector迭代是使用C原生指针，而list则是使用类来实现，这点python的设计是与list一致的。
4. 异常控制流：这里需要密切注意一下，其执行流程如下：
   RAISE_VARARGS抛出异常-->发现PyTryBlock-->初始化异常信息-->从线程状态中取出异常信息-->入栈-->跳转到exception块-->异常匹配-->执行块内代码-->跳转到finally-->执行完后继续执行当前frame的代码。注意一旦没有发现PyTryBlock或者异常不匹配都会跳到finally展开堆栈空间。

第九章、python虚拟机中的函数机制
1. 调用函数时会创建新的pyFrameObject对象，整个函数链会形成PyFrameObject对象链。
2. PyFunctionObject对象：Python中函数也是一个对象，其抽象就是通过类来实现。结构如下
   typedef struct{
       PyObject_HEAD;
       PyObject *func_code; frame对象
       PyObject *func_global; 运行时的global空间
       PyObject *func_default; 默认参数
       PyObject *func_closure; 用于实现闭包
       PyObject *func_doc; 文档
       PyObject *func_name;函数__name__属性
       PyObject *func_dict; 函数__dict__属性
       PyObject *func_weakerflist;
       PyObject *func_module; 可以是任何对象
   }
   pyfunction对象与pycode对象不同，前者是动态的，是运行时的结果，由def语句创建，包含了一个函数执行所必须的信息，比如上下文信息，而后者是静态编译的，是编译时结果，在一段python代码中只会有一个pycode，却可以包含多个函数对象。
   python虚拟机中函数的声明与实现是分离开的，这是python隐藏的一个秘密。从语法上将def是函数的声明语句，而从虚拟机执行角度来讲，def是动态的创建了一个函数对象，但是需要注意的是函数对象创建完成后，其内部的代码被保存到了一个code对象中，所以当声明函数时会先把它载入运行时栈，在创建函数（MAKE_FUCTION指令）时将其弹出，根据它和当前frame中保存的global等信息通过PyFuc_new创建函数对象，其中MAKE_FUNCTION指令还会处理参数问题。而对函数的调用是通过call_function函数来调用的。针对一般函数python有自己的快速通道，创建新的frame对象，而对于python独有的函数则不会走快速通道。
   位置参数：func(a,b="c",*args,**kwargs):a位置参数，b为键参数，args为扩展位置参数，kwargs是扩展键参数。虚拟机在执行CALL_FUNCTION时会先获取参数。
   
第十章、python虚拟机之类机制
1. python中类也是对象，即一切皆为对象，python中共有三种类：type对象（表示python内置的类型）、class（程序员自定义）、instance（实例对象）。在python2.2之前type与class是有区别的，type不能被继承，而现在type和class已经一致了，可以看做同一种类型。与此同时对象之间的关系也有两种：is-kind-of（基类与子类的关系）、is-instance-of（实例与类的关系）。对于前者可以用__base__、__bases__（多基类）来进行探测，对于后者可以用__class__、type、instance来探测。需要注意实例对象和class对象的方法以及属性是不一样的。
2. metaclass对象：其实就是type(A)得到的结果为type的对象，即<type 'type'>对象，这意味着他们是可以被继承的，即可以作为其他对象的type。class对象的创建也是利用了metaclass对象。
3.在python中任何一个对象都有type，instance对象的type必定是class对象，class对象的type必定是metaclass，而object则是万物之母。python2.2之前之所以type对象不能被继承是因为没有在type中寻找某个属性的机制。而python2.2之后为type对象增加了tp_dict（dict）对象，通过查找dict来寻找属性。这里引出可调用的概念，class对象内部实现了__call__（默认实现，可重写）函数它才是可调用的，而其实例对象则是通过PyObject_call函数来调用call完成可调用性的。实际上来说__call__就是()的重载，因此python中使用()操作符有时会报XXX object is not callable.
4. 在python中，会在启动时对python的整个类型系统进行初始化，初始化从Py_Readytypes开始，调用PyType_ready对class对象（包括type和class）进行初始化，对于内置的type，会对其进行完善（比如tp_dict填充），而对于class（用户自定义）则需要创建、申请内存、完善等操作。处理时会先获取基类，当基类没有初始化则对基类进行初始化（__base__\__bases__处理的结果）。
5. 填充tp_dict：slotdefs、slot、descripter，slot存放着一个操作对应的信息，但是它不是对象，不能直接存放到tp_dict中，因此被包装到了descripter，descripter填充了tp_dict。为了dict的get_item实现，slot被存放到了slotdefs数组中并进行了排序。
6. 确定MRO：method resolve order：针对多继承，不想java只支持单继承，python实现了多继承就必须确定基类方法的解析顺序（也就是子类多不同基类重名函数的调用机制），PyType_ready在初始化的时候通过函数mro_interanl完成mro顺序的建立，python虚拟机会建立一个tuple对象，保存着class对象的循序，mro顺序的建立就是根据这个tuple里面class对象的顺序。mro存放了class对象的所有直接、间接基类，然后将自身没有的操作从mro里面拷贝出来完成继承。
7. 填充子类列表：会将基类所有的子类填充到tp_subclasses中，它是一个列表，通过__subclass__()方法获取子类列表。至此初始化完成。

8. 同函数一样，类的声明与定义也会分离，其成员函数也会分离。创建对象的步骤：
   1）获取动态元信息并入栈（type是什么，占用多少内存，有多少属性与方法）
   2）获取class名称与基类列表
   3）调用build_class创建class对象，然后将其压入运行时栈
   对于instance调用class对象的__call__方法即会创建。
9. 成员函数的绑定：pyfunc对象和instance对象的绑定是通过pymethod对象完成的，它是一个具有缓冲池的对象。成员函数中的self参数其实就隐藏在这个对象中，它是一个位置参数，因此名称是不是self都无所谓，self只是大家约定成俗的而已。这种访问方式称为bound method，对应的unbound method方式则应该称为A.f，即class对象的函数调用。区别在于A.f的self需要我们自己传递。


第十一章 python运行环境初始化
1. 进程初始化：python的初始化是从py_initializeEX开始的，在此之前也做了诸多工作，但真正开始是从这里，它先启动核心进程pyInterpreterstate（有next指针，实际是一组核心的进程），然后启动多个pythreadstate（多个），每个thread加载不同的模块、函数等等。在此期间python会加载buildin、sys等系统模块。
2. 加载buildin modules：加载modules的时候，python interpreter会创建PyDictObject，维护所有的modules，对于每个module会创建module对象，为module设置name、doc等属性，然后填充其他属性及函数，遍历整个模块，将每一个method封装为PyCFunction对象，该对象也采用了缓冲池技术。
3. 加载sys module：与buildin差不多，这里注意会设置整个python的搜索路径
4. 创建__main__ module,创建site-specified搜索路径。
5. 创建完成后激活虚拟机，注意交互方式运行和脚本运行是没有太大区别的，最终都是进入同一个虚拟机。

第十二章 python模块的动态加载机制
1. 通过每个model内部维护的module dict来加载，dir()函数可以列出当前模块内的所有符号表，当导入新的模块时可以看到它发生变化，也可以用__dict__属性导出（注意python自带的交互器与ipython的输出是不一样的），dict导出的东西和__builtins__导出的差不多，前者包含后者，其实他们都是python初始化时维护的__builtins__与__dict__。
2. 当module嵌套时，实际上他们是互不影响的，他们拥有自己的符号表。利用id()函数可以轻易的查看某个对象甚至是模块的ID，eg(id(max)),id(caffe2)
   利用sys.modules可以列出当前python环境下所有的modules，他是一个字典，可以用key来判断是不是安装了某个module，eg:sys.module['caffe2']，结果是module名称及其路径。
3. package机制：必须加入__init__.py机制，导入A.b后再导入A.c，A下面的__init__.py仅会被导入一次，这是因为包的结果是树型的，在python中被拆为A,b,c这样的集合，当python发现某个部分被导入后，后面就不会再导入了（实际是A导入后维护了一个__path__，到导入c时python只会在A的路径中搜索，不会再全局搜索）。
   from A import b 与 import A.b的区别：from将b放入了当前局部空间，而不是像import一样作为A的属性存在。前者通过dir函数只能找到b，后者则可以找到A。如果加上as B 则 只能找到B，这是python内部的映射机制，实际都是映射到A.b。
   对于导入的东西可以用del语句将其从dict中删除，但不是真正的删除，python维持了一个module pool，用于缓存，避免动态加载每次都要保存，del删除后只是在代码中不可访问，但实际上依旧存在于pool中，如果要重载，则可以利用reload函数。
   python在import的时候回先加锁，import完成之后解锁，避免多线程造成的影响。
4. find搜索：当import时其__path__被加入find_modules，以供搜索。
5. py_cache文件夹：工程目录下有__main__.py文件，和其他将要调用的模块时。如果只有当前运行的脚本 "__main__"，则不会生成 __pycache__ 的文件。python会将工程下的文件都编译成pyc字节码包含各种pycodeobject，然后存放到该文件中。python调用的时候-B就不会出现了。

第十三章 python多线程机制
1. python中线程是操作系统的原生线程，python仅仅提供了一个全局解释器（GIL）来互斥线程对解释器的使用。GIL是一个霸道的排他锁，当一个线程获得解释器的访问权之后，GIL就会对解释器加锁，其他线程必须排队使用，哪怕机器是多核CPU的也不行，这也使得机器退回了单核的状态，这种方式有利有弊，在单处理器上GIL多线程的效果是好的，但是如果是多处理器那效果就差多了，甚至不如单线程快。解决方式是使用multiprecessing库而不是Thread库，前者是多进程版本，利用IPC通信，在共享设置上却是要弱一点。
2. python线程调度是模拟了系统的调度机制，内部维护了一个时钟（模拟系统时钟中断），在N条指令之后进行中断，这个时钟值可以用sys.getcheckinterval来获取，事实上，这个值也被用来检测是否有异步事件的发生。同样可以用set进行调节。中断之后解释器就会强制挂起当前线程，处理线程链中的下一个线程，下一个线程的选择是利用底层系统的调度机制决定的，python不会插手，因此说python线程是原生的，而不是像坊间所说是模拟出来的。注意python一开始是不支持多线程的，GIL也不会创建，线程调度不会启动，但是一旦用户激活了线程机制，那么即使只有一个线程，python也会调度，这样会造成资源的浪费。
3. python中的thread库是python builtins的，threading是标准库中的。但是貌似在3中thread已经不复存在了。当用户创建了线程后，python就会意识到进入了多线程机制，调度就会开始了。在win32下，python GIL多线程环境创建后，GIL会使用底层系统的线程对象，其核心是win32的Event内核对象，GIL保留了当前线程的ID，hevent（Event）、锁的拥有者。其本质就是一把锁。

第十四章 内存管理
1. python中内存管理有两套机制：DEBUG与非DEBUG，一般使用的是非DEBUG，这个有编译时的参数PTMALLOC_DEBUG控制。内存管理分为四层：object specify memory、PyObj memeory（PyObj API）、Py raw memory（PyMem API）、底层c的malloc机制，python只管理前三层，后面的不再管理。PyRaw是基于c实现的，主要是为了跨平台的可移植性。PyMem API提供类似c中malloc的功能，这一块仅仅是对malloc的包装，GC真正的藏身之处是Pyobj API。
2. 小块空间的内存池：python中大多是小块内存的操作，因此频繁的申请与释放会影响效率，于是内存池应运而生，整个内存池机制分为block、pool、arena、内存池，前三者都是可见的，后者只是一个概念的东西，其级别依次递增。
3. block是一个确定大小的内存块，上限是256字节，为了性能，在32位和64位上都是8字节对齐。python中有不同种类的block，对应不同的大小，其种类为size class，对应的是block的级别，从0-31，对应8字节-256字节，每一级多8字节。注意block是一个概念上的东西，python中是没有实体与之对应的，但是却有管理对象pool。
4. pool：pool是一组block的集合。通常pool是一个系统内存页，一般为4KB，管理多个block。在其内部维护了使用的block链以及free的block链，并提供一定的交互。
5. arena：pool的集合。arena的大小一般是256kb，一般是64个block。arena被组织到一个数组中，这个数组包含多个arena，即为通用小块内存池，但是arena的管理却是通过链表来的，也就是说其内存与管理是分开的，这就表明在某一时刻二者需要建立联系，因此将与pool建立联系的称为使用，未建立的称为free。
6. 小块内存与大块内存的分界点是256字节，当小于256字节时，python在内存池中分配内存，大于时退化为malloc行为。
7. 引用计数之垃圾回收：与主流的垃圾回收机制相比优点在于实时性，引用为0即销毁。弱点在于执行效率需要额外的操作，以及循环引用、互引用等致命弱点。因此在引用计数的基础上，python引入了标记--清除和分代收集的清除技术。
8. 三色标记模型：
   1）寻找根对象的集合，这些对象是全局引用和函数栈中的引用，是不可能被删除的
   2）从这个集合开始沿着每个元素的一个引用往下遍历，如果能到达某个对象A，那么它就是可到达的，可达的对象也不能被删除，这个阶段即为垃圾检测。
   3）检测完毕后将可达对象保留，不可达对象的内存被回收。
   实际上垃圾回收只关注continer对象，这些对象（dict、list）等才有可能循环引用其他对象，想int等对象是不可能出现类似情况的。上述集合实际上构成了一个有向图，当垃圾收集开始时所有节点被标记为白色，意味着不可达，当一个对象可达时被标记为灰色，灰色对象要检查其引用情况，检查过的被标记为黑色。
   那么python是如何关注这些continaer对象的呢，实际上所有的continer对象在创建后都被加入了一条信息PyGC_head，他在PyObject_Head之前，表示它是一个可收集的对象，这个东西里面包含了前向、后向链表指针，以及gc_ref，指针用于将该对象链入可收集对象链表之中。
9. 分代收集模式:其依据原理是一定数量的内存块生存周期短，而其他的周期长，生存时间越长越不可能是垃圾，这也是java的策略。在内存中将内存块按照生存时间划分不同的代，生存时间越长的代检测的频率越小。在python中代的表示形式实际就是可收集链表，每个链表代表一个代，python中主要利用三代模型。
10. 标记清除模式：将内存链表一分为二：root 与 unreachable，对于后者进行标记，完成垃圾检测任务。然后进行垃圾回收。
11. gc模块：手动收集垃圾






